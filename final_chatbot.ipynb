{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>일은 왜 해도 해도 끝이 없을까? 화가 난다.</td>\n",
       "      <td>많이 힘드시겠어요. 주위에 의논할 상대가 있나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.</td>\n",
       "      <td>급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...</td>\n",
       "      <td>회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...</td>\n",
       "      <td>관련 없는 심부름을 모두 하게 되어서 노여우시군요. 어떤 것이 상황을 나아질 수 있...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.</td>\n",
       "      <td>무시하는 것 같은 태도에 화가 나셨군요. 상대방의 어떤 행동이 그런 감정을 유발하는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145958</th>\n",
       "      <td>함께 친하게 지내던 동네 언니 동생들과 빈자리를 조금이나마 채울까 해.</td>\n",
       "      <td>지인분들과 좋은 시간 보내셨으면 좋겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145959</th>\n",
       "      <td>사람들을 볼 때 의심하고 불신하는 마음을 억눌러야겠어. 사람들을 색안경을 끼고 보지...</td>\n",
       "      <td>원하시는 대로 가지고 계시던 걱정이 잘 해결되셨으면 좋겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145960</th>\n",
       "      <td>너 정말 똑똑하구나?</td>\n",
       "      <td>고마워요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145961</th>\n",
       "      <td>좋은 밤 보내</td>\n",
       "      <td>안녕히 주무세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145962</th>\n",
       "      <td>큰 위로가 됬어</td>\n",
       "      <td>도움이 되었다니 기뻐요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145963 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Q  \\\n",
       "0                               일은 왜 해도 해도 끝이 없을까? 화가 난다.   \n",
       "1          이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.   \n",
       "2       회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...   \n",
       "3       직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...   \n",
       "4                   얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.   \n",
       "...                                                   ...   \n",
       "145958            함께 친하게 지내던 동네 언니 동생들과 빈자리를 조금이나마 채울까 해.   \n",
       "145959  사람들을 볼 때 의심하고 불신하는 마음을 억눌러야겠어. 사람들을 색안경을 끼고 보지...   \n",
       "145960                                        너 정말 똑똑하구나?   \n",
       "145961                                            좋은 밤 보내   \n",
       "145962                                           큰 위로가 됬어   \n",
       "\n",
       "                                                        A  \n",
       "0                             많이 힘드시겠어요. 주위에 의논할 상대가 있나요?  \n",
       "1                급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?  \n",
       "2       회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...  \n",
       "3       관련 없는 심부름을 모두 하게 되어서 노여우시군요. 어떤 것이 상황을 나아질 수 있...  \n",
       "4       무시하는 것 같은 태도에 화가 나셨군요. 상대방의 어떤 행동이 그런 감정을 유발하는...  \n",
       "...                                                   ...  \n",
       "145958                            지인분들과 좋은 시간 보내셨으면 좋겠어요.  \n",
       "145959                 원하시는 대로 가지고 계시던 걱정이 잘 해결되셨으면 좋겠어요.  \n",
       "145960                                              고마워요.  \n",
       "145961                                          안녕히 주무세요.  \n",
       "145962                                      도움이 되었다니 기뻐요.  \n",
       "\n",
       "[145963 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('preprocessing_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145963\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "MAX_SAMPLES = 145963\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    # 양쪽의 공백을 제거합니다.\n",
    "    sentence = sentence.strip()\n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    # 여러 개의 공백을 하나의 공백으로 치환합니다.\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    # (0-9 가-힣 \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"[^0-9가-힣?.!,]+\", \" \", sentence) #한글 전처리\n",
    "    # 최종적으로 문장의 양쪽에 있는 공백을 제거합니다.\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "# 데이터셋의 질문과 답변을 각각 inputs, outputs에 저장\n",
    "def load_conversations():\n",
    "    inputs, outputs = [], []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "      # 전처리 후 리스트에 추가합니다.\n",
    "        inputs.append(preprocess_sentence(data['Q'][i])) #questions\n",
    "        outputs.append(preprocess_sentence(data['A'][i])) #answers\n",
    "\n",
    "        if len(inputs) >= MAX_SAMPLES:  # 데이터 샘플의 최대 개수에 도달한 것으로 간주\n",
    "            return inputs, outputs\n",
    "        \n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 145963\n",
      "전체 샘플 수 : 145963\n"
     ]
    }
   ],
   "source": [
    "#로드한 데이터의 샘플 수를 확인\n",
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
    "questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 21번째 질문 샘플: 어제도 야근 오늘도 야근이야 . 너무 힘들어 .\n",
      "전처리 후의 21번째 답변 샘플: 야근이 많아서 힘드신 것 같아요 . 어떤 상황인지 자세히 말씀해 주시겠어요 ?\n"
     ]
    }
   ],
   "source": [
    "#21번째 샘플을 출력해 질문과 답변이 병렬적으로 잘 저장은 되었는지 확인\n",
    "#전처리 함수에서 의도했던 전처리가 진행되었는지 확인\n",
    "print('전처리 후의 21번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 21번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SubwordTextEncoder 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어장(Vocabulary) 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 단어에 고유한 정수 인덱스를 부여하기 위해 질문과 답변 데이터셋에 대해서 Vocabulary 생성.\n",
    "# 질문과 답변 데이터셋을 합쳐서 전체 데이터로 취급\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
    "# target_vocab_size=2**13: vocabulary의 크기를 2^13으로 설정\n",
    "\n",
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "# 시작 토큰은 대화의 시작, 종료 토큰은 대화 종료를 의미합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "# vocabulary에 각 단어에 대한 고유한 정수 인덱스가 부여되며, 이를 통해 텍스트 데이터를 모델의 입력으로 변환할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8238]\n",
      "END_TOKEN의 번호 : [8239]\n"
     ]
    }
   ],
   "source": [
    "#시작 토큰과 종료 토큰에 부여된 정수를 출력\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8240\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 단어를 고유한 정수로 인코딩(Integer encoding) & 패딩(Padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [2928, 13, 1811, 8014, 1788, 1811, 495, 2, 8, 135, 1]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [1811, 5, 703, 2115, 6, 89, 2, 35, 5903, 170, 289, 424, 3]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 21번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))\n",
    "# tokenizer.encode(): 주어진 텍스트를 vocabulary에 따라 정수 인덱스로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGdCAYAAADwjmIIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwN0lEQVR4nO3de3DUVZ7//1dCSIJId7hs0vQYIDuyXIQBJBjiBdclRZCoE8UZwQjUmJHVSZSbQFDJ4DUQFhWQJYNjDVYJK7IlGQwKZIIShRAgmOEemR3kInbifEO6AQUC+fz+mF8+ZQtIwA5NH56Pqk+V/Tnv/vR5B+x+cdJ9OsyyLEsAAACGCQ/2BAAAAJoDIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYKSIYE8gmBoaGnTkyBG1adNGYWFhwZ4OAABoAsuydOzYMbndboWHX3i95poOOUeOHFF8fHywpwEAAC7DoUOHdMMNN1xw/JoOOW3atJH0zx+Sw+EI8mwAAEBT+Hw+xcfH26/jF3JNh5zGX1E5HA5CDgAAIeZibzXhjccAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARooI9gRgni45qy5a8+XMtCswEwDAtYyVHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEa65JBTWlqqe++9V263W2FhYSosLLxg7eOPP66wsDC9/vrrfudra2uVkZEhh8OhmJgYZWZm6vjx434127dv1x133KHo6GjFx8crPz//nOsvX75c3bt3V3R0tHr37q0PP/zwUtsBAACGuuSQc+LECfXp00cLFiz40boVK1Zo06ZNcrvd54xlZGRo165dKi4uVlFRkUpLSzV27Fh73OfzaciQIercubMqKio0e/ZszZgxQ4sWLbJrNm7cqJEjRyozM1Off/650tPTlZ6erp07d15qSwAAwEBhlmVZl33nsDCtWLFC6enpfue/+uorJSUlac2aNUpLS9P48eM1fvx4SdKePXvUs2dPbdmyRYmJiZKk1atXa9iwYTp8+LDcbrcWLlyoZ599Vh6PR5GRkZKknJwcFRYWau/evZKkhx56SCdOnFBRUZH9uAMHDlTfvn1VUFDQpPn7fD45nU55vV45HI7L/THgB7rkrLpozZcz067ATAAAJmrq63fA35PT0NCgUaNGafLkybrpppvOGS8rK1NMTIwdcCQpJSVF4eHhKi8vt2sGDRpkBxxJSk1NVVVVlY4ePWrXpKSk+F07NTVVZWVlF5zbqVOn5PP5/A4AAGCmgIecWbNmKSIiQk899dR5xz0ej2JjY/3ORUREqF27dvJ4PHZNXFycX03j7YvVNI6fT15enpxOp33Ex8dfWnMAACBkBDTkVFRUaO7cuVq8eLHCwsICeemAmDZtmrxer30cOnQo2FMCAADNJKAh59NPP1VNTY06deqkiIgIRURE6MCBA5o0aZK6dOkiSXK5XKqpqfG735kzZ1RbWyuXy2XXVFdX+9U03r5YTeP4+URFRcnhcPgdAADATAENOaNGjdL27dtVWVlpH263W5MnT9aaNWskScnJyaqrq1NFRYV9v3Xr1qmhoUFJSUl2TWlpqerr6+2a4uJidevWTW3btrVrSkpK/B6/uLhYycnJgWwJAACEqIhLvcPx48f1t7/9zb69f/9+VVZWql27durUqZPat2/vV9+yZUu5XC5169ZNktSjRw8NHTpUjz32mAoKClRfX6/s7GyNGDHC/rj5ww8/rOeff16ZmZmaOnWqdu7cqblz5+q1116zrztu3DjdeeedmjNnjtLS0vTuu+9q69atfh8zBwAA165LDjlbt27VXXfdZd+eOHGiJGnMmDFavHhxk66xZMkSZWdna/DgwQoPD9fw4cM1b948e9zpdGrt2rXKyspS//791aFDB+Xm5vrtpXPrrbdq6dKleu655/TMM8+oa9euKiwsVK9evS61JYQwPq4OALiQn7RPTqhjn5zmcSWDByEHAK49QdsnBwAA4GpAyAEAAEYi5AAAACNd8huPgSulKe+3AQDgQljJAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiX1yYDy+3woArk2EHAQFG/0BAJobv64CAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMFJEsCcAXA265Ky6aM2XM9OuwEwAAIFCyAECiLAEAFcPfl0FAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADDSJYec0tJS3XvvvXK73QoLC1NhYaE9Vl9fr6lTp6p3795q3bq13G63Ro8erSNHjvhdo7a2VhkZGXI4HIqJiVFmZqaOHz/uV7N9+3bdcccdio6OVnx8vPLz88+Zy/Lly9W9e3dFR0erd+/e+vDDDy+1HQAAYKhLDjknTpxQnz59tGDBgnPGvv32W23btk3Tp0/Xtm3b9P7776uqqkr33XefX11GRoZ27dql4uJiFRUVqbS0VGPHjrXHfT6fhgwZos6dO6uiokKzZ8/WjBkztGjRIrtm48aNGjlypDIzM/X5558rPT1d6enp2rlz56W2BAAADBRmWZZ12XcOC9OKFSuUnp5+wZotW7bolltu0YEDB9SpUyft2bNHPXv21JYtW5SYmChJWr16tYYNG6bDhw/L7XZr4cKFevbZZ+XxeBQZGSlJysnJUWFhofbu3StJeuihh3TixAkVFRXZjzVw4ED17dtXBQUFTZq/z+eT0+mU1+uVw+G4zJ8Cfqgpu/6GoqbsVMyOxwDQ/Jr6+t3s78nxer0KCwtTTEyMJKmsrEwxMTF2wJGklJQUhYeHq7y83K4ZNGiQHXAkKTU1VVVVVTp69Khdk5KS4vdYqampKisru+BcTp06JZ/P53cAAAAzNWvIOXnypKZOnaqRI0faScvj8Sg2NtavLiIiQu3atZPH47Fr4uLi/Goab1+spnH8fPLy8uR0Ou0jPj7+pzUIAACuWs0Wcurr6/XrX/9almVp4cKFzfUwl2TatGnyer32cejQoWBPCQAANJNm+RbyxoBz4MABrVu3zu/3ZS6XSzU1NX71Z86cUW1trVwul11TXV3tV9N4+2I1jePnExUVpaioqMtvDAAAhIyAr+Q0Bpx9+/bpL3/5i9q3b+83npycrLq6OlVUVNjn1q1bp4aGBiUlJdk1paWlqq+vt2uKi4vVrVs3tW3b1q4pKSnxu3ZxcbGSk5MD3RIAAAhBlxxyjh8/rsrKSlVWVkqS9u/fr8rKSh08eFD19fV68MEHtXXrVi1ZskRnz56Vx+ORx+PR6dOnJUk9evTQ0KFD9dhjj2nz5s3asGGDsrOzNWLECLndbknSww8/rMjISGVmZmrXrl1atmyZ5s6dq4kTJ9rzGDdunFavXq05c+Zo7969mjFjhrZu3ars7OwA/FgAAECou+SQs3XrVvXr10/9+vWTJE2cOFH9+vVTbm6uvvrqK61cuVKHDx9W37591bFjR/vYuHGjfY0lS5aoe/fuGjx4sIYNG6bbb7/dbw8cp9OptWvXav/+/erfv78mTZqk3Nxcv710br31Vi1dulSLFi1Snz599L//+78qLCxUr169fsrPAwAAGOIn7ZMT6tgnp3mwT85Pvw4A4MKumn1yAAAAgoGQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIEcGeABAquuSsCvYUAACXgJUcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjHTJIae0tFT33nuv3G63wsLCVFhY6DduWZZyc3PVsWNHtWrVSikpKdq3b59fTW1trTIyMuRwOBQTE6PMzEwdP37cr2b79u264447FB0drfj4eOXn558zl+XLl6t79+6Kjo5W79699eGHH15qOwAAwFCXHHJOnDihPn36aMGCBecdz8/P17x581RQUKDy8nK1bt1aqampOnnypF2TkZGhXbt2qbi4WEVFRSotLdXYsWPtcZ/PpyFDhqhz586qqKjQ7NmzNWPGDC1atMiu2bhxo0aOHKnMzEx9/vnnSk9PV3p6unbu3HmpLQEAAAOFWZZlXfadw8K0YsUKpaenS/rnKo7b7dakSZP09NNPS5K8Xq/i4uK0ePFijRgxQnv27FHPnj21ZcsWJSYmSpJWr16tYcOG6fDhw3K73Vq4cKGeffZZeTweRUZGSpJycnJUWFiovXv3SpIeeughnThxQkVFRfZ8Bg4cqL59+6qgoKBJ8/f5fHI6nfJ6vXI4HJf7Y8APdMlZFewpXNW+nJkW7CkAQEhr6ut3QN+Ts3//fnk8HqWkpNjnnE6nkpKSVFZWJkkqKytTTEyMHXAkKSUlReHh4SovL7drBg0aZAccSUpNTVVVVZWOHj1q13z/cRprGh/nfE6dOiWfz+d3AAAAMwU05Hg8HklSXFyc3/m4uDh7zOPxKDY21m88IiJC7dq186s53zW+/xgXqmkcP5+8vDw5nU77iI+Pv9QWAQBAiLimPl01bdo0eb1e+zh06FCwpwQAAJpJQEOOy+WSJFVXV/udr66utsdcLpdqamr8xs+cOaPa2lq/mvNd4/uPcaGaxvHziYqKksPh8DsAAICZAhpyEhIS5HK5VFJSYp/z+XwqLy9XcnKyJCk5OVl1dXWqqKiwa9atW6eGhgYlJSXZNaWlpaqvr7driouL1a1bN7Vt29au+f7jNNY0Pg4AALi2XXLIOX78uCorK1VZWSnpn282rqys1MGDBxUWFqbx48frpZde0sqVK7Vjxw6NHj1abrfb/gRWjx49NHToUD322GPavHmzNmzYoOzsbI0YMUJut1uS9PDDDysyMlKZmZnatWuXli1bprlz52rixIn2PMaNG6fVq1drzpw52rt3r2bMmKGtW7cqOzv7p/9UAABAyIu41Dts3bpVd911l327MXiMGTNGixcv1pQpU3TixAmNHTtWdXV1uv3227V69WpFR0fb91myZImys7M1ePBghYeHa/jw4Zo3b5497nQ6tXbtWmVlZal///7q0KGDcnNz/fbSufXWW7V06VI999xzeuaZZ9S1a1cVFhaqV69el/WDAAAAZvlJ++SEOvbJaR7sk/Pj2CcHAH6aoOyTAwAAcLUg5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAI13yd1fh2sZXNgAAQgUrOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEgBDzlnz57V9OnTlZCQoFatWunnP/+5XnzxRVmWZddYlqXc3Fx17NhRrVq1UkpKivbt2+d3ndraWmVkZMjhcCgmJkaZmZk6fvy4X8327dt1xx13KDo6WvHx8crPzw90OwAAIEQFPOTMmjVLCxcu1BtvvKE9e/Zo1qxZys/P1/z58+2a/Px8zZs3TwUFBSovL1fr1q2VmpqqkydP2jUZGRnatWuXiouLVVRUpNLSUo0dO9Ye9/l8GjJkiDp37qyKigrNnj1bM2bM0KJFiwLdEgAACEFh1veXWALgnnvuUVxcnN566y373PDhw9WqVSu98847sixLbrdbkyZN0tNPPy1J8nq9iouL0+LFizVixAjt2bNHPXv21JYtW5SYmChJWr16tYYNG6bDhw/L7XZr4cKFevbZZ+XxeBQZGSlJysnJUWFhofbu3dukufp8PjmdTnm9XjkcjkD+GIzVJWdVsKcQ8r6cmRbsKQBASGvq63fAV3JuvfVWlZSU6IsvvpAk/fWvf9Vnn32mu+++W5K0f/9+eTwepaSk2PdxOp1KSkpSWVmZJKmsrEwxMTF2wJGklJQUhYeHq7y83K4ZNGiQHXAkKTU1VVVVVTp69Oh553bq1Cn5fD6/AwAAmCki0BfMycmRz+dT9+7d1aJFC509e1Yvv/yyMjIyJEkej0eSFBcX53e/uLg4e8zj8Sg2NtZ/ohERateunV9NQkLCOddoHGvbtu05c8vLy9Pzzz8fgC4BAMDVLuArOe+9956WLFmipUuXatu2bXr77bf1X//1X3r77bcD/VCXbNq0afJ6vfZx6NChYE8JAAA0k4Cv5EyePFk5OTkaMWKEJKl37946cOCA8vLyNGbMGLlcLklSdXW1OnbsaN+vurpaffv2lSS5XC7V1NT4XffMmTOqra217+9yuVRdXe1X03i7seaHoqKiFBUV9dObBAAAV72Ar+R8++23Cg/3v2yLFi3U0NAgSUpISJDL5VJJSYk97vP5VF5eruTkZElScnKy6urqVFFRYdesW7dODQ0NSkpKsmtKS0tVX19v1xQXF6tbt27n/VUVAAC4tgQ85Nx77716+eWXtWrVKn355ZdasWKFXn31Vd1///2SpLCwMI0fP14vvfSSVq5cqR07dmj06NFyu91KT0+XJPXo0UNDhw7VY489ps2bN2vDhg3Kzs7WiBEj5Ha7JUkPP/ywIiMjlZmZqV27dmnZsmWaO3euJk6cGOiWAABACAr4r6vmz5+v6dOn63e/+51qamrkdrv1n//5n8rNzbVrpkyZohMnTmjs2LGqq6vT7bffrtWrVys6OtquWbJkibKzszV48GCFh4dr+PDhmjdvnj3udDq1du1aZWVlqX///urQoYNyc3P99tIBAADXroDvkxNK2Cfn0rFPzk/HPjkA8NMEbZ8cAACAqwEhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIwUEewJ4OrRJWdVsKcAAEDAsJIDAACMxEoOcIU1ZcXsy5lpV2AmAGA2VnIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGKlZQs5XX32lRx55RO3bt1erVq3Uu3dvbd261R63LEu5ubnq2LGjWrVqpZSUFO3bt8/vGrW1tcrIyJDD4VBMTIwyMzN1/Phxv5rt27frjjvuUHR0tOLj45Wfn98c7QAAgBAU8JBz9OhR3XbbbWrZsqU++ugj7d69W3PmzFHbtm3tmvz8fM2bN08FBQUqLy9X69atlZqaqpMnT9o1GRkZ2rVrl4qLi1VUVKTS0lKNHTvWHvf5fBoyZIg6d+6siooKzZ49WzNmzNCiRYsC3RIAAAhBYZZlWYG8YE5OjjZs2KBPP/30vOOWZcntdmvSpEl6+umnJUler1dxcXFavHixRowYoT179qhnz57asmWLEhMTJUmrV6/WsGHDdPjwYbndbi1cuFDPPvusPB6PIiMj7ccuLCzU3r17mzRXn88np9Mpr9crh8MRgO5DW5ecVcGeAv5/X85MC/YUAOCq1dTX74Cv5KxcuVKJiYn61a9+pdjYWPXr109vvvmmPb5//355PB6lpKTY55xOp5KSklRWViZJKisrU0xMjB1wJCklJUXh4eEqLy+3awYNGmQHHElKTU1VVVWVjh49Gui2AABAiAl4yPn73/+uhQsXqmvXrlqzZo2eeOIJPfXUU3r77bclSR6PR5IUFxfnd7+4uDh7zOPxKDY21m88IiJC7dq186s53zW+/xg/dOrUKfl8Pr8DAACYKSLQF2xoaFBiYqJeeeUVSVK/fv20c+dOFRQUaMyYMYF+uEuSl5en559/PqhzAAAAV0bAV3I6duyonj17+p3r0aOHDh48KElyuVySpOrqar+a6upqe8zlcqmmpsZv/MyZM6qtrfWrOd81vv8YPzRt2jR5vV77OHTo0OW0CAAAQkDAQ85tt92mqqoqv3NffPGFOnfuLElKSEiQy+VSSUmJPe7z+VReXq7k5GRJUnJysurq6lRRUWHXrFu3Tg0NDUpKSrJrSktLVV9fb9cUFxerW7dufp/k+r6oqCg5HA6/AwAAmCngIWfChAnatGmTXnnlFf3tb3/T0qVLtWjRImVlZUmSwsLCNH78eL300ktauXKlduzYodGjR8vtdis9PV3SP1d+hg4dqscee0ybN2/Whg0blJ2drREjRsjtdkuSHn74YUVGRiozM1O7du3SsmXLNHfuXE2cODHQLQEAgBAU8PfkDBgwQCtWrNC0adP0wgsvKCEhQa+//royMjLsmilTpujEiRMaO3as6urqdPvtt2v16tWKjo62a5YsWaLs7GwNHjxY4eHhGj58uObNm2ePO51OrV27VllZWerfv786dOig3Nxcv710AADAtSvg++SEEvbJ8cc+OVcP9skBgAsL2j45AAAAVwNCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAI0UEewK4MrrkrAr2FAAAuKJYyQEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYKRmDzkzZ85UWFiYxo8fb587efKksrKy1L59e11//fUaPny4qqur/e538OBBpaWl6brrrlNsbKwmT56sM2fO+NV88sknuvnmmxUVFaUbb7xRixcvbu52AABAiGjWkLNlyxb94Q9/0C9+8Qu/8xMmTNAHH3yg5cuXa/369Tpy5IgeeOABe/zs2bNKS0vT6dOntXHjRr399ttavHixcnNz7Zr9+/crLS1Nd911lyorKzV+/Hj99re/1Zo1a5qzJQAAECKaLeQcP35cGRkZevPNN9W2bVv7vNfr1VtvvaVXX31V//Ef/6H+/fvrT3/6kzZu3KhNmzZJktauXavdu3frnXfeUd++fXX33XfrxRdf1IIFC3T69GlJUkFBgRISEjRnzhz16NFD2dnZevDBB/Xaa681V0sAACCENFvIycrKUlpamlJSUvzOV1RUqL6+3u989+7d1alTJ5WVlUmSysrK1Lt3b8XFxdk1qamp8vl82rVrl13zw2unpqba1zifU6dOyefz+R0AAMBMzbLj8bvvvqtt27Zpy5Yt54x5PB5FRkYqJibG73xcXJw8Ho9d8/2A0zjeOPZjNT6fT999951atWp1zmPn5eXp+eefv+y+AABA6Aj4Ss6hQ4c0btw4LVmyRNHR0YG+/E8ybdo0eb1e+zh06FCwpwQAAJpJwENORUWFampqdPPNNysiIkIRERFav3695s2bp4iICMXFxen06dOqq6vzu191dbVcLpckyeVynfNpq8bbF6txOBznXcWRpKioKDkcDr8DAACYKeAhZ/DgwdqxY4cqKyvtIzExURkZGfZ/t2zZUiUlJfZ9qqqqdPDgQSUnJ0uSkpOTtWPHDtXU1Ng1xcXFcjgc6tmzp13z/Ws01jReAwAAXNsC/p6cNm3aqFevXn7nWrdurfbt29vnMzMzNXHiRLVr104Oh0NPPvmkkpOTNXDgQEnSkCFD1LNnT40aNUr5+fnyeDx67rnnlJWVpaioKEnS448/rjfeeENTpkzRo48+qnXr1um9997TqlV82zYAAGimNx5fzGuvvabw8HANHz5cp06dUmpqqv77v//bHm/RooWKior0xBNPKDk5Wa1bt9aYMWP0wgsv2DUJCQlatWqVJkyYoLlz5+qGG27QH//4R6WmpgajJQAAcJUJsyzLCvYkgsXn88npdMrr9Rr//pwuOaxwhZIvZ6YFewoAcNVq6us3310FAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABgpKDseA/hxTdm8kQ0DAeDHsZIDAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYKSLYE8BP1yVnVbCnAADAVYeVHAAAYCRCDgAAMFLAQ05eXp4GDBigNm3aKDY2Vunp6aqqqvKrOXnypLKystS+fXtdf/31Gj58uKqrq/1qDh48qLS0NF133XWKjY3V5MmTdebMGb+aTz75RDfffLOioqJ04403avHixYFuBwAAhKiAvydn/fr1ysrK0oABA3TmzBk988wzGjJkiHbv3q3WrVtLkiZMmKBVq1Zp+fLlcjqdys7O1gMPPKANGzZIks6ePau0tDS5XC5t3LhRX3/9tUaPHq2WLVvqlVdekSTt379faWlpevzxx7VkyRKVlJTot7/9rTp27KjU1NRAtwVcdZryXqwvZ6ZdgZkAwNUpzLIsqzkf4JtvvlFsbKzWr1+vQYMGyev16l/+5V+0dOlSPfjgg5KkvXv3qkePHiorK9PAgQP10Ucf6Z577tGRI0cUFxcnSSooKNDUqVP1zTffKDIyUlOnTtWqVau0c+dO+7FGjBihuro6rV69uklz8/l8cjqd8nq9cjgcgW/+CuGNx7gQQg4AEzX19bvZ35Pj9XolSe3atZMkVVRUqL6+XikpKXZN9+7d1alTJ5WVlUmSysrK1Lt3bzvgSFJqaqp8Pp927dpl13z/Go01jdc4n1OnTsnn8/kdAADATM0achoaGjR+/Hjddttt6tWrlyTJ4/EoMjJSMTExfrVxcXHyeDx2zfcDTuN449iP1fh8Pn333XfnnU9eXp6cTqd9xMfH/+QeAQDA1alZQ05WVpZ27typd999tzkfpsmmTZsmr9drH4cOHQr2lAAAQDNpts0As7OzVVRUpNLSUt1www32eZfLpdOnT6uurs5vNae6uloul8uu2bx5s9/1Gj999f2aH34iq7q6Wg6HQ61atTrvnKKiohQVFfWTewMAAFe/gK/kWJal7OxsrVixQuvWrVNCQoLfeP/+/dWyZUuVlJTY56qqqnTw4EElJydLkpKTk7Vjxw7V1NTYNcXFxXI4HOrZs6dd8/1rNNY0XgMAAFzbAr6Sk5WVpaVLl+rPf/6z2rRpY7+Hxul0qlWrVnI6ncrMzNTEiRPVrl07ORwOPfnkk0pOTtbAgQMlSUOGDFHPnj01atQo5efny+Px6LnnnlNWVpa9EvP444/rjTfe0JQpU/Too49q3bp1eu+997RqFZ80AgAAzbCSs3DhQnm9Xv37v/+7OnbsaB/Lli2za1577TXdc889Gj58uAYNGiSXy6X333/fHm/RooWKiorUokULJScn65FHHtHo0aP1wgsv2DUJCQlatWqViouL1adPH82ZM0d//OMf2SMHAABIugL75FzN2CcHpmOfHAAmumr2yQEAAAgGQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYKRm+xZyAMHXlN2w2RUZgKlYyQEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjMRmgFe5pmzmBgAAzkXIAa5xTQ3S7IwMINTw6yoAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACPxEXIATdKUj5rzMXMAVxNWcgAAgJFYyQEQMKz2ALiasJIDAACMRMgBAABGIuQAAAAjEXIAAICReOMxgCuKNycDuFJYyQEAAEYK+ZWcBQsWaPbs2fJ4POrTp4/mz5+vW265JdjTapKm/IsWuBax2gMgEEI65CxbtkwTJ05UQUGBkpKS9Prrrys1NVVVVVWKjY0N9vQANKNA/SOBsASYK8yyLCvYk7hcSUlJGjBggN544w1JUkNDg+Lj4/Xkk08qJyfnovf3+XxyOp3yer1yOBzNPd1zsJID4HIQzHCta+rrd8iu5Jw+fVoVFRWaNm2afS48PFwpKSkqKys7731OnTqlU6dO2be9Xq+kf/6wgqHh1LdBeVwAoa3ThOUXrdn5fOoVmAkQHI2v2xdbpwnZkPOPf/xDZ8+eVVxcnN/5uLg47d2797z3ycvL0/PPP3/O+fj4+GaZIwAEi/P1YM8AaH7Hjh2T0+m84HjIhpzLMW3aNE2cONG+3dDQoNraWrVv315hYWFNvo7P51N8fLwOHToUlF9zXQn0aI5roc9roUfp2ujzWuhRujb6bM4eLcvSsWPH5Ha7f7QuZENOhw4d1KJFC1VXV/udr66ulsvlOu99oqKiFBUV5XcuJibmsufgcDiM/cvZiB7NcS30eS30KF0bfV4LPUrXRp/N1eOPreA0Ctl9ciIjI9W/f3+VlJTY5xoaGlRSUqLk5OQgzgwAAFwNQnYlR5ImTpyoMWPGKDExUbfccotef/11nThxQr/5zW+CPTUAABBkIR1yHnroIX3zzTfKzc2Vx+NR3759tXr16nPejBxoUVFR+v3vf3/Or75MQo/muBb6vBZ6lK6NPq+FHqVro8+roceQ3icHAADgQkL2PTkAAAA/hpADAACMRMgBAABGIuQAAAAjEXIu0YIFC9SlSxdFR0crKSlJmzdvDvaULlteXp4GDBigNm3aKDY2Vunp6aqqqvKrOXnypLKystS+fXtdf/31Gj58+DkbMIaSmTNnKiwsTOPHj7fPmdLjV199pUceeUTt27dXq1at1Lt3b23dutUetyxLubm56tixo1q1aqWUlBTt27cviDO+NGfPntX06dOVkJCgVq1a6ec//7lefPFFv++uCcUeS0tLde+998rtdissLEyFhYV+403pqba2VhkZGXI4HIqJiVFmZqaOHz9+Bbu4uB/rs76+XlOnTlXv3r3VunVrud1ujR49WkeOHPG7xtXe58X+LL/v8ccfV1hYmF5//XW/8yb0uGfPHt13331yOp1q3bq1BgwYoIMHD9rjV/I5l5BzCZYtW6aJEyfq97//vbZt26Y+ffooNTVVNTU1wZ7aZVm/fr2ysrK0adMmFRcXq76+XkOGDNGJEyfsmgkTJuiDDz7Q8uXLtX79eh05ckQPPPBAEGd9+bZs2aI//OEP+sUvfuF33oQejx49qttuu00tW7bURx99pN27d2vOnDlq27atXZOfn6958+apoKBA5eXlat26tVJTU3Xy5MkgzrzpZs2apYULF+qNN97Qnj17NGvWLOXn52v+/Pl2TSj2eOLECfXp00cLFiw473hTesrIyNCuXbtUXFysoqIilZaWauzYsVeqhSb5sT6//fZbbdu2TdOnT9e2bdv0/vvvq6qqSvfdd59f3dXe58X+LButWLFCmzZtOu9XEoR6j//3f/+n22+/Xd27d9cnn3yi7du3a/r06YqOjrZrruhzroUmu+WWW6ysrCz79tmzZy23223l5eUFcVaBU1NTY0my1q9fb1mWZdXV1VktW7a0li9fbtfs2bPHkmSVlZUFa5qX5dixY1bXrl2t4uJi684777TGjRtnWZY5PU6dOtW6/fbbLzje0NBguVwua/bs2fa5uro6Kyoqyvqf//mfKzHFnywtLc169NFH/c498MADVkZGhmVZZvQoyVqxYoV9uyk97d6925Jkbdmyxa756KOPrLCwMOurr766YnO/FD/s83w2b95sSbIOHDhgWVbo9XmhHg8fPmz97Gc/s3bu3Gl17tzZeu211+wxE3p86KGHrEceeeSC97nSz7ms5DTR6dOnVVFRoZSUFPtceHi4UlJSVFZWFsSZBY7X65UktWvXTpJUUVGh+vp6v567d++uTp06hVzPWVlZSktL8+tFMqfHlStXKjExUb/61a8UGxurfv366c0337TH9+/fL4/H49en0+lUUlJSyPR56623qqSkRF988YUk6a9//as+++wz3X333ZLM6PGHmtJTWVmZYmJilJiYaNekpKQoPDxc5eXlV3zOgeL1ehUWFmZ/v6AJfTY0NGjUqFGaPHmybrrppnPGQ73HhoYGrVq1Sv/2b/+m1NRUxcbGKikpye9XWlf6OZeQ00T/+Mc/dPbs2XN2U46Li5PH4wnSrAKnoaFB48eP12233aZevXpJkjwejyIjI8/5EtNQ6/ndd9/Vtm3blJeXd86YKT3+/e9/18KFC9W1a1etWbNGTzzxhJ566im9/fbbkmT3Esp/f3NycjRixAh1795dLVu2VL9+/TR+/HhlZGRIMqPHH2pKTx6PR7GxsX7jERERateuXcj2ffLkSU2dOlUjR460v9jRhD5nzZqliIgIPfXUU+cdD/Uea2pqdPz4cc2cOVNDhw7V2rVrdf/99+uBBx7Q+vXrJV3559yQ/loHBE5WVpZ27typzz77LNhTCahDhw5p3LhxKi4u9vudsGkaGhqUmJioV155RZLUr18/7dy5UwUFBRozZkyQZxcY7733npYsWaKlS5fqpptuUmVlpcaPHy+3221Mj/jnm5B//etfy7IsLVy4MNjTCZiKigrNnTtX27ZtU1hYWLCn0ywaGhokSb/85S81YcIESVLfvn21ceNGFRQU6M4777zic2Ilp4k6dOigFi1anPMO8OrqarlcriDNKjCys7NVVFSkjz/+WDfccIN93uVy6fTp06qrq/OrD6WeKyoqVFNTo5tvvlkRERGKiIjQ+vXrNW/ePEVERCguLi7ke5Skjh07qmfPnn7nevToYX+iobGXUP77O3nyZHs1p3fv3ho1apQmTJhgr9CZ0OMPNaUnl8t1zocfzpw5o9ra2pDruzHgHDhwQMXFxfYqjhT6fX766aeqqalRp06d7OeiAwcOaNKkSerSpYuk0O+xQ4cOioiIuOhz0ZV8ziXkNFFkZKT69++vkpIS+1xDQ4NKSkqUnJwcxJldPsuylJ2drRUrVmjdunVKSEjwG+/fv79atmzp13NVVZUOHjwYMj0PHjxYO3bsUGVlpX0kJiYqIyPD/u9Q71GSbrvttnM+/v/FF1+oc+fOkqSEhAS5XC6/Pn0+n8rLy0Omz2+//Vbh4f5PWS1atLD/9WhCjz/UlJ6Sk5NVV1eniooKu2bdunVqaGhQUlLSFZ/z5WoMOPv27dNf/vIXtW/f3m881PscNWqUtm/f7vdc5Ha7NXnyZK1Zs0ZS6PcYGRmpAQMG/Ohz0RV/XQn4W5kN9u6771pRUVHW4sWLrd27d1tjx461YmJiLI/HE+ypXZYnnnjCcjqd1ieffGJ9/fXX9vHtt9/aNY8//rjVqVMna926ddbWrVut5ORkKzk5OYiz/um+/+kqyzKjx82bN1sRERHWyy+/bO3bt89asmSJdd1111nvvPOOXTNz5kwrJibG+vOf/2xt377d+uUvf2klJCRY3333XRBn3nRjxoyxfvazn1lFRUXW/v37rffff9/q0KGDNWXKFLsmFHs8duyY9fnnn1uff/65Jcl69dVXrc8//9z+VFFTeho6dKjVr18/q7y83Prss8+srl27WiNHjgxWS+f1Y32ePn3auu+++6wbbrjBqqys9Hs+OnXqlH2Nq73Pi/1Z/tAPP11lWaHf4/vvv2+1bNnSWrRokbVv3z5r/vz5VosWLaxPP/3UvsaVfM4l5Fyi+fPnW506dbIiIyOtW265xdq0aVOwp3TZJJ33+NOf/mTXfPfdd9bvfvc7q23bttZ1111n3X///dbXX38dvEkHwA9Djik9fvDBB1avXr2sqKgoq3v37taiRYv8xhsaGqzp06dbcXFxVlRUlDV48GCrqqoqSLO9dD6fzxo3bpzVqVMnKzo62vrXf/1X69lnn/V7EQzFHj/++OPz/n84ZswYy7Ka1tP/+3//zxo5cqR1/fXXWw6Hw/rNb35jHTt2LAjdXNiP9bl///4LPh99/PHH9jWu9j4v9mf5Q+cLOSb0+NZbb1k33nijFR0dbfXp08cqLCz0u8aVfM4Ns6zvbRcKAABgCN6TAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICR/j9XcQWNcAdNfAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 각 질문의 길이 시각화\n",
    "len_q = []\n",
    "\n",
    "for q in questions:\n",
    "    len_q.append(len(q))\n",
    "\n",
    "plt.hist(len_q, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터에서 길이가 80이상인 질문의 비율 확인하기\n",
    "cnt = 0\n",
    "for q in questions:\n",
    "    if len(q) > 80:\n",
    "        cnt+=1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005193096880716346"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt / 145963\n",
    "# 0.519"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "약 0.52% >> 무시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 80\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 80 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 80으로 모든 데이터셋을 패딩\n",
    "  # tokenized_inputs의 모든 샘플에 대해 패딩을 적용하여\n",
    "  # 입력 데이터셋 생성\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  # 출력 데이터셋 생성\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8240\n",
      "필터링 후의 질문 샘플 개수: 145963\n",
      "필터링 후의 답변 샘플 개수: 145963\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teacher Forcing 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 20000   # 데이터셋을 섞기 위한 버퍼 크기\n",
    "\n",
    "# 입력과 출력 데이터를 데이터셋으로 변환합니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # 디코더의 입력, END_TOKEN이 제거된다.\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]     # START_TOKEN이 제거된다.\n",
    "    },\n",
    "))\n",
    "\n",
    "# 캐시를 사용하면 데이터를 파일에서 매번 다시 읽어오지 않고 메모리에 저장하여 처리 속도를 향상시킵니다.\n",
    "dataset = dataset.cache()\n",
    "# 데이터셋을 BUFFER_SIZE만큼 섞습니다.\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "# 배치 크기만큼 데이터를 묶어서 처리합니다.\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "# 데이터를 미리 읽어서 메모리에 준비하도록 설정합니다.\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "# tf.data.experimental.AUTOTUNE: 자동으로 최적의 개수를 설정하여 데이터를 준비합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 모델 구성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 포지셔널 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 시퀀스의 단어 위치 정보를 고려하기 위해 사용\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  # 객체의 설정 정보를 반환하는 메서드\n",
    "  def get_config(self):\n",
    "        return {\"position\": self.position, \"d_model\": self.d_model} \n",
    "  \n",
    "  # 위치 인코딩에 사용할 각도 배열을 생성하는 메서드\n",
    "  # Transformer의 위치 인코딩은 일정한 각도 값을 사용하여 위치 정보를 표현\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    # tf.pow(): 거듭제곱 값 계산\n",
    "    # tf.cast(): 배열의 dtype 변경\n",
    "    return position * angles\n",
    "\n",
    "  # 입력 시퀀스의 단어 위치 정보를 담은 위치 인코딩 벡터를 생성하는 메서드\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  # 위치 인코딩을 실제 입력에 적용하는 메서드\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) 스케일드 닷 프로덕트 어텐션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쿼리(Query), 키(Key), 밸류(Value)로 이루어진 입력에 대해 어텐션 가중치를 계산\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  # 어텐션 가중치를 계산\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) 멀티 헤드 어텐션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer 모델에서 사용되는 멀티헤드 어텐션 레이어를 정의\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    # 각 Query, Key, Value에 대한 Dense layer 정의\n",
    "    # 멀티헤드 어텐션의 연산에 사용됩니다.\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  # 멀티헤드 어텐션을 수행하기 위해 입력을 헤드 개수만큼 나누는 메서드\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  # 멀티헤드 어텐션을 수행하는 메서드\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    #################################\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) 패딩 마스킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 마스크를 생성하는 함수\n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) 룩 어헤드 마스킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 셀프 어텐션 레이어에서 사용\n",
    "# 다음 단어를 예측할 때 현재 단어 이후의 토큰들에 대한 가중치를 0으로 만든다.\n",
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  # 삼각형 마스킹\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  # 패딩 마스크를 생성하는 함수 호출\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  # 룩어헤드 마스크와 패딩 마스크 중 더 큰 값으로 이루어진 최종 마스크 반환\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "# 디코더에서 현재까지 생성된 토큰들만을 이용하여 다음 단어를 예측하는데 도움을 준다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 레이어\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    # 인코더 레이어에 들어가는 입력으로 단어의 임베딩 벡터가 들어갑니다.\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    # >> 현재 단어에 대한 정보를 다른 모든 단어에 대해 어텐션 가중치를 계산하여 얻습니다.\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization 적용\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 fully-connected layer\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # fully-connected layer의 결과는 Dropout과 LayerNormalization 적용\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 정의\n",
    "# 임베딩 레이어와 포지셔널 인코딩을 적용하여 구성\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  # 입력 텐서 정의\n",
    "  # 현재 인코더에 들어가는 토큰의 인덱스 시퀀스\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 정의\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  # (단어장의 크기, 차원 크기)\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  # 임베딩 차원 수로 정규화 수행 >> 연산 안정성을 높임\n",
    "  # 트랜스포머 모델의 설계에 기반한 연산\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  # 임베딩 벡터에 포지셔널 인코딩 적용\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층 구현\n",
    "  # 이전 레이어의 출력과 패딩마스크를 입력으로 받아 연속적으로 적용합니다.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 레이어\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    # 입력 텐서 정의\n",
    "    # 디코더에 들어가는 토큰의 인덱스 시퀀스\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    # 인코더의 출력 텐서 정의\n",
    "    # 인코더-디코더 어텐션을 수행할 때 사용\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    # 룩어헤드 마스크 정의\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    # 패딩 마스크 정의\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': look_ahead_mask\n",
    "        })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization 적용\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    # 입력으로 이전 서브 레이어의 출력과 인코더의 출력을 받아 수행\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1,\n",
    "            'key': enc_outputs,\n",
    "            'value': enc_outputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는 Dropout과 LayerNormalization 적용\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세 번째 서브 레이어 : 2개의 fully-connected layer\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    # units: fully-connected layer의 뉴런 수\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    # outputs의 출력을 d_model 차원으로 변환\n",
    "\n",
    "    # fully-connected layer의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 정의\n",
    "# 임베딩 레이어와 포지셔널 인코딩을 적용하여 구성\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    # 입력 텐서 정의\n",
    "    # 디코더에 들어가는 토큰의 인덱스 시퀀스\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    # 인코더의 출력 텐서 정의\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    # 룩어헤드 마스크 정의\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    # 위치 정보를 임베딩 벡터에 추가\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout 적용\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 디코더 레이어 쌓기\n",
    "    # 입력으로 이전 레이어의 출력과 인코더의 출력, 룩어헤드 마스크, 패딩 마스크 사용\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8) 트랜스포머"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#앞서 사용한 인코더 층 함수와 디코더 층 함수를 사용하여 트랜스포머 함수를 정의\n",
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    # 인코더의 입력 텐서 정의\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    # 디코더의 입력 텐서 정의\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더 레이어 구성\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더 레이어 구성\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # fully-connected layer\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "    # 인코더의 입력과 디코더의 입력, 그리고 최종 예측값 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " encoder (Functional)           (None, None, 256)    3163648     ['inputs[0][0]',                 \n",
      "                                                                  'enc_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
      "                                e)                                                                \n",
      "                                                                                                  \n",
      " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, None, 256)    3691008     ['dec_inputs[0][0]',             \n",
      "                                                                  'encoder[0][0]',                \n",
      "                                                                  'look_ahead_mask[0][0]',        \n",
      "                                                                  'dec_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, None, 8240)   2117680     ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,972,336\n",
      "Trainable params: 8,972,336\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "# 트랜스포머 모델 구성\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실 함수(Loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1)) # 디코더 출력 시퀀스의 시작 토큰을 제외하고 사용\n",
    "  \n",
    "  # 다항 분류에서 출력으로 softmax 를 사용할 때 y_true가 범주의 인덱스로 되어 있을 때 사용\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "  # from_logits=True: 모델의 출력값이 확률 분포를 나타내는 형태(logit)\n",
    "  # reduction='none': 각 시퀀스 단위의 손실값을 유지\n",
    "\n",
    "  # 디코더의 입력 시퀀스는 패딩이 적용되어 있기에 손실 계산에서 배제\n",
    "  # 패딩이 아닌 위치에 마스크 생성, 해당 마스크를 손실값과 곱하여 패딩 부분을 0으로 만들어준다.\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "커스텀 된 학습률(Learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  # 학습률을 조정하는 함수\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1141/1141 [==============================] - 108s 94ms/step - loss: 0.4532 - accuracy: 0.0580\n",
      "Epoch 2/30\n",
      "1141/1141 [==============================] - 107s 94ms/step - loss: 0.4206 - accuracy: 0.0607\n",
      "Epoch 3/30\n",
      "1141/1141 [==============================] - 109s 96ms/step - loss: 0.3899 - accuracy: 0.0638\n",
      "Epoch 4/30\n",
      "1141/1141 [==============================] - 110s 97ms/step - loss: 0.3663 - accuracy: 0.0665\n",
      "Epoch 5/30\n",
      "1141/1141 [==============================] - 110s 97ms/step - loss: 0.3470 - accuracy: 0.0687\n",
      "Epoch 6/30\n",
      "1141/1141 [==============================] - 111s 97ms/step - loss: 0.3309 - accuracy: 0.0708\n",
      "Epoch 7/30\n",
      "1141/1141 [==============================] - 110s 97ms/step - loss: 0.3169 - accuracy: 0.0727\n",
      "Epoch 8/30\n",
      "1141/1141 [==============================] - 110s 96ms/step - loss: 0.3045 - accuracy: 0.0744\n",
      "Epoch 9/30\n",
      "1141/1141 [==============================] - 111s 97ms/step - loss: 0.2935 - accuracy: 0.0760\n",
      "Epoch 10/30\n",
      "1141/1141 [==============================] - 110s 97ms/step - loss: 0.2837 - accuracy: 0.0775\n",
      "Epoch 11/30\n",
      "1141/1141 [==============================] - 112s 98ms/step - loss: 0.2747 - accuracy: 0.0789\n",
      "Epoch 12/30\n",
      "1141/1141 [==============================] - 112s 98ms/step - loss: 0.2667 - accuracy: 0.0802\n",
      "Epoch 13/30\n",
      "1141/1141 [==============================] - 111s 98ms/step - loss: 0.2592 - accuracy: 0.0814\n",
      "Epoch 14/30\n",
      "1141/1141 [==============================] - 112s 98ms/step - loss: 0.2525 - accuracy: 0.0824\n",
      "Epoch 15/30\n",
      "1141/1141 [==============================] - 112s 98ms/step - loss: 0.2462 - accuracy: 0.0835\n",
      "Epoch 16/30\n",
      "1141/1141 [==============================] - 111s 97ms/step - loss: 0.2403 - accuracy: 0.0845\n",
      "Epoch 17/30\n",
      "1141/1141 [==============================] - 110s 97ms/step - loss: 0.2351 - accuracy: 0.0854\n",
      "Epoch 18/30\n",
      "1141/1141 [==============================] - 111s 97ms/step - loss: 0.2300 - accuracy: 0.0863\n",
      "Epoch 19/30\n",
      "1141/1141 [==============================] - 111s 97ms/step - loss: 0.2253 - accuracy: 0.0871\n",
      "Epoch 20/30\n",
      "1141/1141 [==============================] - 111s 98ms/step - loss: 0.2208 - accuracy: 0.0879\n",
      "Epoch 21/30\n",
      "1141/1141 [==============================] - 112s 98ms/step - loss: 0.2169 - accuracy: 0.0886\n",
      "Epoch 22/30\n",
      "1141/1141 [==============================] - 113s 99ms/step - loss: 0.2130 - accuracy: 0.0893\n",
      "Epoch 23/30\n",
      "1141/1141 [==============================] - 112s 98ms/step - loss: 0.2091 - accuracy: 0.0900\n",
      "Epoch 24/30\n",
      "1141/1141 [==============================] - 111s 97ms/step - loss: 0.2057 - accuracy: 0.0907\n",
      "Epoch 25/30\n",
      "1141/1141 [==============================] - 111s 97ms/step - loss: 0.2023 - accuracy: 0.0912\n",
      "Epoch 26/30\n",
      "1141/1141 [==============================] - 111s 98ms/step - loss: 0.1991 - accuracy: 0.0919\n",
      "Epoch 27/30\n",
      "1141/1141 [==============================] - 110s 97ms/step - loss: 0.1961 - accuracy: 0.0924\n",
      "Epoch 28/30\n",
      "1141/1141 [==============================] - 111s 97ms/step - loss: 0.1933 - accuracy: 0.0929\n",
      "Epoch 29/30\n",
      "1141/1141 [==============================] - 110s 97ms/step - loss: 0.1905 - accuracy: 0.0936\n",
      "Epoch 30/30\n",
      "1141/1141 [==============================] - 111s 97ms/step - loss: 0.1880 - accuracy: 0.0940\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss 시각화\n",
    "y_loss = history.history['loss']\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_loss)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예측(inference)으로 챗봇 테스트하기\n",
    "def decoder_inference(sentence):\n",
    "  # 입력 문장 전처리\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장.\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계 수행\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#임의의 입력 문장에 대해서 decoder_inference() 함수를 호출하여 챗봇의 대답을 얻는다.\n",
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 날씨는 어때?\n",
      "출력 : 어느새 여행이라니 정말 신나시겠어요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'어느새 여행이라니 정말 신나시겠어요 .'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#임의의 문장으로부터 챗봇의 대답을 얻어봅시다.\n",
    "sentence_generation('오늘 날씨는 어때?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 놀러가고 싶다\n",
      "출력 : 빨리 놀러가길 바랄게요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'빨리 놀러가길 바랄게요 .'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('놀러가고 싶다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너는 이름이 뭐야?\n",
      "출력 : 기분이 안좋았겠어요 . 어떻게 하면 기분이 나아질 수 있을까요 ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'기분이 안좋았겠어요 . 어떻게 하면 기분이 나아질 수 있을까요 ?'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('너는 이름이 뭐야?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 저녁 뭐 먹을지 고민돼\n",
      "출력 : 저녁 먹을 시간이 촉박하시군요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저녁 먹을 시간이 촉박하시군요 .'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('저녁 뭐 먹을지 고민돼')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나 너무 힘들어\n",
      "출력 : 이럴 때 도와줄 친구가 있을까요 ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'이럴 때 도와줄 친구가 있을까요 ?'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('나 너무 힘들어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 머리가 복잡해\n",
      "출력 : 이 복잡함을 나눌 사람이 있었으면 좋겠네요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'이 복잡함을 나눌 사람이 있었으면 좋겠네요 .'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('머리가 복잡해')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 행복해\n",
      "출력 : 행복한 하루가 되겠군요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'행복한 하루가 되겠군요 .'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('행복해')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 재밌는 이야기 해줘\n",
      "출력 : 재밌는 말드리면서 기분이 나아지길 바라요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'재밌는 말드리면서 기분이 나아지길 바라요 .'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('재밌는 이야기 해줘')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 영화 보러 갈래?\n",
      "출력 : 영화 감염으로 영화관람을 풀고 싶으시군요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'영화 감염으로 영화관람을 풀고 싶으시군요 .'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('영화 보러 갈래?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 질문 좀 그만해\n",
      "출력 : 면접 결과가 좋은 결과가 있기를 바라요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'면접 결과가 좋은 결과가 있기를 바라요 .'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('질문 좀 그만해')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 귀찮아\n",
      "출력 : 어떤 점이 귀찮으신가요 ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'어떤 점이 귀찮으신가요 ?'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('귀찮아')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
